{
  "version": 3,
  "sources": ["base-types.ts"],
  "sourcesContent": ["import * as ec2 from '../../../aws-ec2';\nimport * as ecr from '../../../aws-ecr';\nimport { DockerImageAsset, DockerImageAssetProps } from '../../../aws-ecr-assets';\nimport * as iam from '../../../aws-iam';\nimport * as kms from '../../../aws-kms';\nimport * as s3 from '../../../aws-s3';\nimport * as sfn from '../../../aws-stepfunctions';\nimport { Duration, Size } from '../../../core';\nimport { Construct } from 'constructs';\n\n/**\n * Task to train a machine learning model using Amazon SageMaker\n */\nexport interface ISageMakerTask extends iam.IGrantable {}\n\n/**\n * Specify the training algorithm and algorithm-specific metadata\n */\nexport interface AlgorithmSpecification {\n\n  /**\n   * Name of the algorithm resource to use for the training job.\n   * This must be an algorithm resource that you created or subscribe to on AWS Marketplace.\n   * If you specify a value for this parameter, you can't specify a value for TrainingImage.\n   *\n   * @default - No algorithm is specified\n   */\n  readonly algorithmName?: string;\n\n  /**\n   * List of metric definition objects. Each object specifies the metric name and regular expressions used to parse algorithm logs.\n   *\n   * @default - No metrics\n   */\n  readonly metricDefinitions?: MetricDefinition[];\n\n  /**\n   * Registry path of the Docker image that contains the training algorithm.\n   *\n   * @default - No Docker image is specified\n   */\n  readonly trainingImage?: DockerImage;\n\n  /**\n   * Input mode that the algorithm supports.\n   *\n   * @default 'File' mode\n   */\n  readonly trainingInputMode?: InputMode;\n}\n\n/**\n *  Describes the training, validation or test dataset and the Amazon S3 location where it is stored.\n *\n */\nexport interface Channel {\n\n  /**\n   * Name of the channel\n   */\n  readonly channelName: string;\n\n  /**\n   * Compression type if training data is compressed\n   *\n   * @default - None\n   */\n  readonly compressionType?: CompressionType;\n\n  /**\n   * The MIME type of the data.\n   *\n   * @default - None\n   */\n  readonly contentType?: string;\n\n  /**\n   * Location of the channel data.\n   */\n  readonly dataSource: DataSource;\n\n  /**\n   * Input mode to use for the data channel in a training job.\n   *\n   * @default - None\n   */\n  readonly inputMode?: InputMode;\n\n  /**\n   * Specify RecordIO as the value when input data is in raw format but the training algorithm requires the RecordIO format.\n   * In this case, Amazon SageMaker wraps each individual S3 object in a RecordIO record.\n   * If the input data is already in RecordIO format, you don't need to set this attribute.\n   *\n   * @default - None\n   */\n  readonly recordWrapperType?: RecordWrapperType;\n\n  /**\n   * Shuffle config option for input data in a channel.\n   *\n   * @default - None\n   */\n  readonly shuffleConfig?: ShuffleConfig;\n}\n\n/**\n * Configuration for a shuffle option for input data in a channel.\n *\n */\nexport interface ShuffleConfig {\n  /**\n   * Determines the shuffling order.\n   */\n  readonly seed: number;\n}\n\n/**\n * Location of the channel data.\n *\n */\nexport interface DataSource {\n  /**\n   * S3 location of the data source that is associated with a channel.\n   */\n  readonly s3DataSource: S3DataSource;\n}\n\n/**\n * S3 location of the channel data.\n *\n * @see https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html\n *\n */\nexport interface S3DataSource {\n  /**\n   * List of one or more attribute names to use that are found in a specified augmented manifest file.\n   *\n   * @default - No attribute names\n   */\n  readonly attributeNames?: string[];\n\n  /**\n   * S3 Data Distribution Type\n   *\n   * @default - None\n   */\n  readonly s3DataDistributionType?: S3DataDistributionType;\n\n  /**\n   * S3 Data Type\n   *\n   * @default S3_PREFIX\n   */\n  readonly s3DataType?: S3DataType;\n\n  /**\n   * S3 Uri\n   */\n  readonly s3Location: S3Location;\n}\n\n/**\n * Configures the S3 bucket where SageMaker will save the result of model training\n */\nexport interface OutputDataConfig {\n  /**\n   * Optional KMS encryption key that Amazon SageMaker uses to encrypt the model artifacts at rest using Amazon S3 server-side encryption.\n   *\n   * @default - Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account\n   */\n  readonly encryptionKey?: kms.IKey;\n\n  /**\n   * Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.\n   */\n  readonly s3OutputLocation: S3Location;\n}\n\n/**\n * Specifies a limit to how long a model training job can run.\n * When the job reaches the time limit, Amazon SageMaker ends the training job.\n *\n */\nexport interface StoppingCondition {\n  /**\n   * The maximum length of time, in seconds, that the training or compilation job can run.\n   *\n   * @default - 1 hour\n   */\n  readonly maxRuntime?: Duration;\n}\n\n/**\n * Specifies the resources, ML compute instances, and ML storage volumes to deploy for model training.\n *\n */\nexport interface ResourceConfig {\n\n  /**\n   * The number of ML compute instances to use.\n   *\n   * @default 1 instance.\n   */\n  readonly instanceCount: number;\n\n  /**\n   * ML compute instance type.\n   *\n   * To provide an instance type from the task input, supply an instance type in the following way\n   * where the value in the task input is an EC2 instance type prepended with \"ml.\":\n   *\n   * ```ts\n   * new ec2.InstanceType(sfn.JsonPath.stringAt('$.path.to.instanceType'));\n   * ```\n   * @see https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ResourceConfig.html#sagemaker-Type-ResourceConfig-InstanceType\n   *\n   * @default ec2.InstanceType(ec2.InstanceClass.M4, ec2.InstanceType.XLARGE)\n   */\n  readonly instanceType: ec2.InstanceType;\n\n  /**\n   * KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the training job.\n   *\n   * @default - Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account\n   */\n  readonly volumeEncryptionKey?: kms.IKey;\n\n  /**\n   * Size of the ML storage volume that you want to provision.\n   *\n   * @default 10 GB EBS volume.\n   */\n  readonly volumeSize: Size;\n}\n\n/**\n * Specifies the VPC that you want your Amazon SageMaker training job to connect to.\n *\n */\nexport interface VpcConfig {\n  /**\n   * VPC\n   */\n  readonly vpc: ec2.IVpc;\n\n  /**\n   * VPC subnets.\n   *\n   * @default - Private Subnets are selected\n   */\n  readonly subnets?: ec2.SubnetSelection;\n}\n\n/**\n * Specifies the metric name and regular expressions used to parse algorithm logs.\n *\n */\nexport interface MetricDefinition {\n\n  /**\n   * Name of the metric.\n   */\n  readonly name: string;\n\n  /**\n   * Regular expression that searches the output of a training job and gets the value of the metric.\n   */\n  readonly regex: string;\n}\n\n/**\n * Stores information about the location of an object in Amazon S3\n *\n */\nexport interface S3LocationConfig {\n\n  /**\n   * Uniquely identifies the resource in Amazon S3\n   */\n  readonly uri: string;\n}\n\n/**\n * Constructs `IS3Location` objects.\n *\n */\nexport abstract class S3Location {\n  /**\n   * An `IS3Location` built with a determined bucket and key prefix.\n   *\n   * @param bucket    is the bucket where the objects are to be stored.\n   * @param keyPrefix is the key prefix used by the location.\n   */\n  public static fromBucket(bucket: s3.IBucket, keyPrefix: string): S3Location {\n    return new StandardS3Location({ bucket, keyPrefix, uri: bucket.urlForObject(keyPrefix) });\n  }\n\n  /**\n   * An `IS3Location` determined fully by a JSON Path from the task input.\n   *\n   * Due to the dynamic nature of those locations, the IAM grants that will be set by `grantRead` and `grantWrite`\n   * apply to the `*` resource.\n   *\n   * @param expression the JSON expression resolving to an S3 location URI.\n   */\n  public static fromJsonExpression(expression: string): S3Location {\n    return new StandardS3Location({ uri: sfn.JsonPath.stringAt(expression) });\n  }\n\n  /**\n   * Called when the S3Location is bound to a StepFunctions task.\n   */\n  public abstract bind(task: ISageMakerTask, opts: S3LocationBindOptions): S3LocationConfig;\n}\n\n/**\n * Options for binding an S3 Location.\n *\n */\nexport interface S3LocationBindOptions {\n  /**\n   * Allow reading from the S3 Location.\n   *\n   * @default false\n   */\n  readonly forReading?: boolean;\n\n  /**\n   * Allow writing to the S3 Location.\n   *\n   * @default false\n   */\n  readonly forWriting?: boolean;\n}\n\n/**\n * Configuration for a using Docker image.\n *\n */\nexport interface DockerImageConfig {\n  /**\n   * The fully qualified URI of the Docker image.\n   */\n  readonly imageUri: string;\n}\n\n/**\n * Creates `IDockerImage` instances.\n *\n */\nexport abstract class DockerImage {\n  /**\n   * Reference a Docker image stored in an ECR repository.\n   *\n   * @param repository the ECR repository where the image is hosted.\n   * @param tag an optional `tag`\n   */\n  public static fromEcrRepository(repository: ecr.IRepository, tag: string = 'latest'): DockerImage {\n    return new StandardDockerImage({ repository, imageUri: repository.repositoryUriForTag(tag) });\n  }\n\n  /**\n   * Reference a Docker image which URI is obtained from the task's input.\n   *\n   * @param expression           the JSON path expression with the task input.\n   * @param allowAnyEcrImagePull whether ECR access should be permitted (set to `false` if the image will never be in ECR).\n   */\n  public static fromJsonExpression(expression: string, allowAnyEcrImagePull = true): DockerImage {\n    return new StandardDockerImage({ imageUri: expression, allowAnyEcrImagePull });\n  }\n\n  /**\n   * Reference a Docker image by it's URI.\n   *\n   * When referencing ECR images, prefer using `inEcr`.\n   *\n   * @param imageUri the URI to the docker image.\n   */\n  public static fromRegistry(imageUri: string): DockerImage {\n    return new StandardDockerImage({ imageUri });\n  }\n\n  /**\n   * Reference a Docker image that is provided as an Asset in the current app.\n   *\n   * @param scope the scope in which to create the Asset.\n   * @param id    the ID for the asset in the construct tree.\n   * @param props the configuration props of the asset.\n   */\n  public static fromAsset(scope: Construct, id: string, props: DockerImageAssetProps): DockerImage {\n    const asset = new DockerImageAsset(scope, id, props);\n    return new StandardDockerImage({ repository: asset.repository, imageUri: asset.imageUri });\n  }\n\n  /**\n   * Called when the image is used by a SageMaker task.\n   */\n  public abstract bind(task: ISageMakerTask): DockerImageConfig;\n}\n\n/**\n * S3 Data Type.\n *\n */\nexport enum S3DataType {\n  /**\n   * Manifest File Data Type\n   */\n  MANIFEST_FILE = 'ManifestFile',\n\n  /**\n   * S3 Prefix Data Type\n   */\n  S3_PREFIX = 'S3Prefix',\n\n  /**\n   * Augmented Manifest File Data Type\n   */\n  AUGMENTED_MANIFEST_FILE = 'AugmentedManifestFile'\n}\n\n/**\n * S3 Data Distribution Type.\n *\n */\nexport enum S3DataDistributionType {\n  /**\n   * Fully replicated S3 Data Distribution Type\n   */\n  FULLY_REPLICATED = 'FullyReplicated',\n\n  /**\n   * Sharded By S3 Key Data Distribution Type\n   */\n  SHARDED_BY_S3_KEY = 'ShardedByS3Key'\n}\n\n/**\n * Define the format of the input data.\n *\n */\nexport enum RecordWrapperType {\n  /**\n   * None record wrapper type\n   */\n  NONE = 'None',\n\n  /**\n   * RecordIO record wrapper type\n   */\n  RECORD_IO = 'RecordIO'\n}\n\n/**\n *  Input mode that the algorithm supports.\n *\n */\nexport enum InputMode {\n  /**\n   * Pipe mode\n   */\n  PIPE = 'Pipe',\n\n  /**\n   * File mode.\n   */\n  FILE = 'File'\n}\n\n/**\n * Compression type of the data.\n *\n */\nexport enum CompressionType {\n  /**\n   * None compression type\n   */\n  NONE = 'None',\n\n  /**\n   * Gzip compression type\n   */\n  GZIP = 'Gzip'\n}\n\n//\n// Create Transform Job types\n//\n\n/**\n * Configures the timeout and maximum number of retries for processing a transform job invocation.\n *\n */\nexport interface ModelClientOptions {\n\n  /**\n   * The maximum number of retries when invocation requests are failing.\n   *\n   * @default 0\n   */\n  readonly invocationsMaxRetries?: number;\n\n  /**\n   * The timeout duration for an invocation request.\n   *\n   * @default Duration.minutes(1)\n   */\n  readonly invocationsTimeout?: Duration;\n}\n\n/**\n *  Dataset to be transformed and the Amazon S3 location where it is stored.\n *\n */\nexport interface TransformInput {\n\n  /**\n   * The compression type of the transform data.\n   *\n   * @default NONE\n   */\n  readonly compressionType?: CompressionType;\n\n  /**\n   * Multipurpose internet mail extension (MIME) type of the data.\n   *\n   * @default - None\n   */\n  readonly contentType?: string;\n\n  /**\n   * S3 location of the channel data\n   */\n  readonly transformDataSource: TransformDataSource;\n\n  /**\n   * Method to use to split the transform job's data files into smaller batches.\n   *\n   * @default NONE\n   */\n  readonly splitType?: SplitType;\n}\n\n/**\n * S3 location of the input data that the model can consume.\n *\n */\nexport interface TransformDataSource {\n\n  /**\n   * S3 location of the input data\n   */\n  readonly s3DataSource: TransformS3DataSource;\n}\n\n/**\n * Location of the channel data.\n *\n */\nexport interface TransformS3DataSource {\n\n  /**\n   * S3 Data Type\n   *\n   * @default 'S3Prefix'\n   */\n  readonly s3DataType?: S3DataType;\n\n  /**\n   * Identifies either a key name prefix or a manifest.\n   */\n  readonly s3Uri: string;\n}\n\n/**\n * S3 location where you want Amazon SageMaker to save the results from the transform job.\n *\n */\nexport interface TransformOutput {\n\n  /**\n   * MIME type used to specify the output data.\n   *\n   * @default - None\n   */\n  readonly accept?: string;\n\n  /**\n   * Defines how to assemble the results of the transform job as a single S3 object.\n   *\n   * @default - None\n   */\n  readonly assembleWith?: AssembleWith;\n\n  /**\n   * AWS KMS key that Amazon SageMaker uses to encrypt the model artifacts at rest using Amazon S3 server-side encryption.\n   *\n   * @default - default KMS key for Amazon S3 for your role's account.\n   */\n  readonly encryptionKey?: kms.IKey;\n\n  /**\n   * S3 path where you want Amazon SageMaker to store the results of the transform job.\n   */\n  readonly s3OutputPath: string;\n}\n\n/**\n * ML compute instances for the transform job.\n *\n */\nexport interface TransformResources {\n\n  /**\n   * Number of ML compute instances to use in the transform job\n   */\n  readonly instanceCount: number;\n\n  /**\n   * ML compute instance type for the transform job.\n   */\n  readonly instanceType: ec2.InstanceType;\n\n  /**\n   * AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached to the ML compute instance(s).\n   *\n   * @default - None\n   */\n  readonly volumeEncryptionKey?: kms.IKey;\n}\n\n/**\n * Properties to define a ContainerDefinition\n *\n * @see https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ContainerDefinition.html\n */\nexport interface ContainerDefinitionOptions {\n  /**\n   * The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.\n   *\n   * @default - None\n   */\n  readonly image?: DockerImage;\n  /**\n   * The environment variables to set in the Docker container\n   *\n   * @default - No variables\n   */\n  readonly environmentVariables?: sfn.TaskInput;\n  /**\n   * The name or Amazon Resource Name (ARN) of the model package to use to create the model.\n   *\n   * @default - None\n   */\n  readonly modelPackageName?: string;\n  /**\n   * Defines how many models the container hosts\n   *\n   * @default - Mode.SINGLE_MODEL\n   */\n  readonly mode?: Mode;\n  /**\n   * This parameter is ignored for models that contain only a PrimaryContainer.\n   * When a ContainerDefinition is part of an inference pipeline,\n   * the value of the parameter uniquely identifies the container for the purposes of logging and metrics.\n   *\n   * @default - None\n   */\n  readonly containerHostName?: string;\n  /**\n   * The S3 path where the model artifacts, which result from model training, are stored.\n   * This path must point to a single gzip compressed tar archive (.tar.gz suffix).\n   * The S3 path is required for Amazon SageMaker built-in algorithms, but not if you use your own algorithms.\n   *\n   * @default - None\n   */\n  readonly modelS3Location?: S3Location;\n}\n\n/**\n * Describes the container, as part of model definition.\n *\n * @see https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ContainerDefinition.html\n */\nexport class ContainerDefinition implements IContainerDefinition {\n\n  constructor(private readonly options: ContainerDefinitionOptions) {}\n\n  /**\n   * Called when the ContainerDefinition type configured on Sagemaker Task\n   */\n  public bind(task: ISageMakerTask): ContainerDefinitionConfig {\n    return {\n      parameters: {\n        ContainerHostname: this.options.containerHostName,\n        Image: this.options.image?.bind(task).imageUri,\n        Mode: this.options.mode,\n        ModelDataUrl: this.options.modelS3Location?.bind(task, { forReading: true }).uri,\n        ModelPackageName: this.options.modelPackageName,\n        Environment: this.options.environmentVariables?.value,\n      },\n    };\n  }\n}\n\n/**\n * Configuration of the container used to host the model\n *\n * @see https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ContainerDefinition.html\n */\nexport interface IContainerDefinition {\n  /**\n   * Called when the ContainerDefinition is used by a SageMaker task.\n   */\n  bind(task: ISageMakerTask): ContainerDefinitionConfig;\n}\n\n/**\n * Configuration options for the ContainerDefinition\n */\nexport interface ContainerDefinitionConfig {\n  /**\n   * Additional parameters to pass to the base task\n   *\n   * @default - No additional parameters passed\n   */\n  readonly parameters?: { [key: string]: any };\n}\n\n/**\n * Specifies how many models the container hosts\n *\n */\nexport enum Mode {\n  /**\n   * Container hosts a single model\n   */\n  SINGLE_MODEL = 'SingleModel',\n  /**\n   * Container hosts multiple models\n   *\n   * @see https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html\n   */\n  MULTI_MODEL = 'MultiModel',\n}\n\n/**\n * Identifies a model that you want to host and the resources to deploy for hosting it.\n *\n * @see  https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ProductionVariant.html\n */\nexport interface ProductionVariant {\n  /**\n   * The size of the Elastic Inference (EI) instance to use for the production variant.\n   *\n   * @default - None\n   */\n  readonly acceleratorType?: AcceleratorType;\n  /**\n   * Number of instances to launch initially.\n   *\n   * @default - 1\n   */\n  readonly initialInstanceCount?: number;\n  /**\n   * Determines initial traffic distribution among all of the models that you specify in the endpoint configuration.\n   *\n   * @default - 1.0\n   */\n  readonly initialVariantWeight?: number;\n  /**\n   * The ML compute instance type\n   */\n  readonly instanceType: ec2.InstanceType;\n  /**\n   * The name of the production variant.\n   */\n  readonly variantName: string;\n  /**\n   * The name of the model that you want to host. This is the name that you specified when creating the model.\n   */\n  readonly modelName: string;\n}\n\n/**\n * The generation of Elastic Inference (EI) instance\n *\n * @see https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n */\nexport class AcceleratorClass {\n  /**\n   * Elastic Inference accelerator 1st generation\n   */\n  public static readonly EIA1 = AcceleratorClass.of('eia1');\n  /**\n   * Elastic Inference accelerator 2nd generation\n   */\n  public static readonly EIA2 = AcceleratorClass.of('eia2');\n  /**\n   * Custom AcceleratorType\n   * @param version - Elastic Inference accelerator generation\n  */\n  public static of(version: string) { return new AcceleratorClass(version); }\n  /**\n   * @param version - Elastic Inference accelerator generation\n   */\n  private constructor(public readonly version: string) { }\n}\n\n/**\n * The size of the Elastic Inference (EI) instance to use for the production variant.\n * EI instances provide on-demand GPU computing for inference\n *\n * @see https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n */\nexport class AcceleratorType {\n  /**\n   * AcceleratorType\n   *\n   * This class takes a combination of a class and size.\n   */\n  public static of(acceleratorClass: AcceleratorClass, instanceSize: ec2.InstanceSize) {\n    return new AcceleratorType(`ml.${acceleratorClass}.${instanceSize}`);\n  }\n\n  constructor(private readonly instanceTypeIdentifier: string) {\n  }\n\n  /**\n   * Return the accelerator type as a dotted string\n   */\n  public toString(): string {\n    return this.instanceTypeIdentifier;\n  }\n}\n\n/**\n * Specifies the number of records to include in a mini-batch for an HTTP inference request.\n *\n */\nexport enum BatchStrategy {\n\n  /**\n   * Fits multiple records in a mini-batch.\n   */\n  MULTI_RECORD = 'MultiRecord',\n\n  /**\n   * Use a single record when making an invocation request.\n   */\n  SINGLE_RECORD = 'SingleRecord'\n}\n\n/**\n * Method to use to split the transform job's data files into smaller batches.\n *\n */\nexport enum SplitType {\n\n  /**\n   * Input data files are not split,\n   */\n  NONE = 'None',\n\n  /**\n   * Split records on a newline character boundary.\n   */\n  LINE = 'Line',\n\n  /**\n   * Split using MXNet RecordIO format.\n   */\n  RECORD_IO = 'RecordIO',\n\n  /**\n   * Split using TensorFlow TFRecord format.\n   */\n  TF_RECORD = 'TFRecord'\n}\n\n/**\n * How to assemble the results of the transform job as a single S3 object.\n *\n */\nexport enum AssembleWith {\n\n  /**\n   * Concatenate the results in binary format.\n   */\n  NONE = 'None',\n\n  /**\n   * Add a newline character at the end of every transformed record.\n   */\n  LINE = 'Line'\n\n}\n\nclass StandardDockerImage extends DockerImage {\n  private readonly allowAnyEcrImagePull: boolean;\n  private readonly imageUri: string;\n  private readonly repository?: ecr.IRepository;\n\n  constructor(opts: { allowAnyEcrImagePull?: boolean, imageUri: string, repository?: ecr.IRepository }) {\n    super();\n\n    this.allowAnyEcrImagePull = !!opts.allowAnyEcrImagePull;\n    this.imageUri = opts.imageUri;\n    this.repository = opts.repository;\n  }\n\n  public bind(task: ISageMakerTask): DockerImageConfig {\n    if (this.repository) {\n      this.repository.grantPull(task);\n    }\n    if (this.allowAnyEcrImagePull) {\n      task.grantPrincipal.addToPrincipalPolicy(new iam.PolicyStatement({\n        actions: [\n          'ecr:BatchCheckLayerAvailability',\n          'ecr:GetDownloadUrlForLayer',\n          'ecr:BatchGetImage',\n        ],\n        resources: ['*'],\n      }));\n    }\n    return {\n      imageUri: this.imageUri,\n    };\n  }\n}\n\nclass StandardS3Location extends S3Location {\n  private readonly bucket?: s3.IBucket;\n  private readonly keyGlob: string;\n  private readonly uri: string;\n\n  constructor(opts: { bucket?: s3.IBucket, keyPrefix?: string, uri: string }) {\n    super();\n    this.bucket = opts.bucket;\n    this.keyGlob = `${opts.keyPrefix || ''}*`;\n    this.uri = opts.uri;\n  }\n\n  public bind(task: ISageMakerTask, opts: S3LocationBindOptions): S3LocationConfig {\n    if (this.bucket) {\n      if (opts.forReading) {\n        this.bucket.grantRead(task, this.keyGlob);\n      }\n      if (opts.forWriting) {\n        this.bucket.grantWrite(task, this.keyGlob);\n      }\n    } else {\n      const actions = new Array<string>();\n      if (opts.forReading) {\n        actions.push('s3:GetObject', 's3:ListBucket');\n      }\n      if (opts.forWriting) {\n        actions.push('s3:PutObject');\n      }\n      task.grantPrincipal.addToPrincipalPolicy(new iam.PolicyStatement({ actions, resources: ['*'] }));\n    }\n    return { uri: this.uri };\n  }\n}\n"],
  "mappings": "igBAEA,iBAAA,QAAA,yBAAA,EACA,IAAA,QAAA,kBAAA,EAGA,IAAA,QAAA,4BAAA,EAwRA,MAAsB,UAAU,OAOhB,YAAW,OAAoB,UAAiB,mEACrD,GAAI,oBAAmB,CAAE,OAAQ,UAAW,IAAK,OAAO,aAAa,SAAS,CAAC,CAAE,QAW5E,oBAAmB,WAAkB,CACjD,MAAO,IAAI,oBAAmB,CAAE,IAAK,IAAI,SAAS,SAAS,UAAU,CAAC,CAAE,GApB5E,QAAA,WAAA,wHAgEA,MAAsB,WAAW,OAOjB,mBAAkB,WAA6B,IAAc,SAAQ,4EAC1E,GAAI,qBAAoB,CAAE,WAAY,SAAU,WAAW,oBAAoB,GAAG,CAAC,CAAE,QAShF,oBAAmB,WAAoB,qBAAuB,GAAI,CAC9E,MAAO,IAAI,qBAAoB,CAAE,SAAU,WAAY,oBAAoB,CAAE,QAUjE,cAAa,SAAgB,CACzC,MAAO,IAAI,qBAAoB,CAAE,QAAQ,CAAE,QAU/B,WAAU,MAAkB,GAAY,MAA4B,iFAChF,KAAM,OAAQ,GAAI,kBAAA,iBAAiB,MAAO,GAAI,KAAK,EACnD,MAAO,IAAI,qBAAoB,CAAE,WAAY,MAAM,WAAY,SAAU,MAAM,QAAQ,CAAE,GAzC7F,QAAA,YAAA,2HAsDA,GAAY,YAAZ,AAAA,UAAY,YAAU,CAIpB,YAAA,cAAA,eAKA,YAAA,UAAA,WAKA,YAAA,wBAAA,uBACF,GAfY,WAAA,QAAA,YAAA,SAAA,WAAU,CAAA,EAAA,EAqBtB,GAAY,wBAAZ,AAAA,UAAY,wBAAsB,CAIhC,wBAAA,iBAAA,kBAKA,wBAAA,kBAAA,gBACF,GAVY,uBAAA,QAAA,wBAAA,SAAA,uBAAsB,CAAA,EAAA,EAgBlC,GAAY,mBAAZ,AAAA,UAAY,mBAAiB,CAI3B,mBAAA,KAAA,OAKA,mBAAA,UAAA,UACF,GAVY,kBAAA,QAAA,mBAAA,SAAA,kBAAiB,CAAA,EAAA,EAgB7B,GAAY,WAAZ,AAAA,UAAY,WAAS,CAInB,WAAA,KAAA,OAKA,WAAA,KAAA,MACF,GAVY,UAAA,QAAA,WAAA,SAAA,UAAS,CAAA,EAAA,EAgBrB,GAAY,iBAAZ,AAAA,UAAY,iBAAe,CAIzB,iBAAA,KAAA,OAKA,iBAAA,KAAA,MACF,GAVY,gBAAA,QAAA,iBAAA,SAAA,gBAAe,CAAA,EAAA,EAmN3B,MAAa,mBAAmB,CAE9B,YAA6B,QAAmC,CAAnC,KAAA,QAAA,wGAKtB,KAAK,KAAoB,sGACvB,CACL,WAAY,CACV,kBAAmB,KAAK,QAAQ,kBAChC,MAAK,IAAE,KAAK,QAAQ,SAAK,MAAA,KAAA,OAAA,OAAA,GAAE,KAAK,IAAI,EAAE,SACtC,KAAM,KAAK,QAAQ,KACnB,aAAY,IAAE,KAAK,QAAQ,mBAAe,MAAA,KAAA,OAAA,OAAA,GAAE,KAAK,KAAM,CAAE,WAAY,EAAI,CAAE,EAAE,IAC7E,iBAAkB,KAAK,QAAQ,iBAC/B,YAAW,IAAE,KAAK,QAAQ,wBAAoB,MAAA,KAAA,OAAA,OAAA,GAAE,SAfxD,QAAA,oBAAA,mJAiDA,GAAY,MAAZ,AAAA,UAAY,MAAI,CAId,MAAA,aAAA,cAMA,MAAA,YAAA,YACF,GAXY,KAAA,QAAA,MAAA,SAAA,KAAI,CAAA,EAAA,EAwDhB,MAAa,gBAAgB,CAiB3B,YAAoC,QAAe,CAAf,KAAA,QAAA,cAJtB,IAAG,QAAe,CAAI,MAAO,IAAI,kBAAiB,OAAO,CAAE,EAb3E,QAAA,iBAAA,0IAIyB,iBAAA,KAAO,iBAAiB,GAAG,MAAM,EAIjC,iBAAA,KAAO,iBAAiB,GAAG,MAAM,EAkB1D,MAAa,eAAe,CAU1B,YAA6B,uBAA8B,CAA9B,KAAA,uBAAA,6BAJf,IAAG,iBAAoC,aAA8B,8KAC1E,GAAI,iBAAgB,MAAM,oBAAoB,cAAc,EAS9D,UAAQ,CACb,MAAO,MAAK,wBAjBhB,QAAA,gBAAA,uIAyBA,GAAY,eAAZ,AAAA,UAAY,eAAa,CAKvB,eAAA,aAAA,cAKA,eAAA,cAAA,cACF,GAXY,cAAA,QAAA,eAAA,SAAA,cAAa,CAAA,EAAA,EAiBzB,GAAY,WAAZ,AAAA,UAAY,WAAS,CAKnB,WAAA,KAAA,OAKA,WAAA,KAAA,OAKA,WAAA,UAAA,WAKA,WAAA,UAAA,UACF,GArBY,UAAA,QAAA,WAAA,SAAA,UAAS,CAAA,EAAA,EA2BrB,GAAY,cAAZ,AAAA,UAAY,cAAY,CAKtB,cAAA,KAAA,OAKA,cAAA,KAAA,MAEF,GAZY,aAAA,QAAA,cAAA,SAAA,aAAY,CAAA,EAAA,EAcxB,MAAM,2BAA4B,YAAW,CAK3C,YAAY,KAAwF,CAClG,MAAK,EAEL,KAAK,qBAAuB,CAAC,CAAC,KAAK,qBACnC,KAAK,SAAW,KAAK,SACrB,KAAK,WAAa,KAAK,WAGlB,KAAK,KAAoB,CAC9B,MAAI,MAAK,YACP,KAAK,WAAW,UAAU,IAAI,EAE5B,KAAK,sBACP,KAAK,eAAe,qBAAqB,GAAI,KAAI,gBAAgB,CAC/D,QAAS,CACP,kCACA,6BACA,qBAEF,UAAW,CAAC,GAAG,EAChB,CAAC,EAEG,CACL,SAAU,KAAK,WAKrB,MAAM,0BAA2B,WAAU,CAKzC,YAAY,KAA8D,CACxE,MAAK,EACL,KAAK,OAAS,KAAK,OACnB,KAAK,QAAU,GAAG,KAAK,WAAa,MACpC,KAAK,IAAM,KAAK,IAGX,KAAK,KAAsB,KAA2B,CAC3D,GAAI,KAAK,OACP,AAAI,KAAK,YACP,KAAK,OAAO,UAAU,KAAM,KAAK,OAAO,EAEtC,KAAK,YACP,KAAK,OAAO,WAAW,KAAM,KAAK,OAAO,MAEtC,CACL,KAAM,SAAU,GAAI,OACpB,AAAI,KAAK,YACP,QAAQ,KAAK,eAAgB,eAAe,EAE1C,KAAK,YACP,QAAQ,KAAK,cAAc,EAE7B,KAAK,eAAe,qBAAqB,GAAI,KAAI,gBAAgB,CAAE,QAAS,UAAW,CAAC,GAAG,CAAC,CAAE,CAAC,EAEjG,MAAO,CAAE,IAAK,KAAK,GAAG",
  "names": []
}
