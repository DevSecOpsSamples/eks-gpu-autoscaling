{
  "version": 3,
  "sources": ["event-source-mapping.ts"],
  "sourcesContent": ["import * as cdk from '../../core';\nimport { Construct } from 'constructs';\nimport { IEventSourceDlq } from './dlq';\nimport { IFunction } from './function-base';\nimport { CfnEventSourceMapping } from './lambda.generated';\n\n/**\n * The type of authentication protocol or the VPC components for your event source's SourceAccessConfiguration\n * @see https://docs.aws.amazon.com/lambda/latest/dg/API_SourceAccessConfiguration.html#SSS-Type-SourceAccessConfiguration-Type\n */\nexport class SourceAccessConfigurationType {\n\n  /**\n   * (MQ) The Secrets Manager secret that stores your broker credentials.\n   */\n  public static readonly BASIC_AUTH = new SourceAccessConfigurationType('BASIC_AUTH');\n\n  /**\n   * The subnets associated with your VPC. Lambda connects to these subnets to fetch data from your Self-Managed Apache Kafka cluster.\n   */\n  public static readonly VPC_SUBNET = new SourceAccessConfigurationType('VPC_SUBNET');\n\n  /**\n   * The VPC security group used to manage access to your Self-Managed Apache Kafka brokers.\n   */\n  public static readonly VPC_SECURITY_GROUP = new SourceAccessConfigurationType('VPC_SECURITY_GROUP');\n\n  /**\n   * The Secrets Manager ARN of your secret key used for SASL SCRAM-256 authentication of your Self-Managed Apache Kafka brokers.\n   */\n  public static readonly SASL_SCRAM_256_AUTH = new SourceAccessConfigurationType('SASL_SCRAM_256_AUTH');\n\n  /**\n   * The Secrets Manager ARN of your secret key used for SASL SCRAM-512 authentication of your Self-Managed Apache Kafka brokers.\n   */\n  public static readonly SASL_SCRAM_512_AUTH = new SourceAccessConfigurationType('SASL_SCRAM_512_AUTH');\n\n  /**\n   * The Secrets Manager ARN of your secret key containing the certificate chain (X.509 PEM), private key (PKCS#8 PEM),\n   * and private key password (optional) used for mutual TLS authentication of your MSK/Apache Kafka brokers.\n   */\n  public static readonly CLIENT_CERTIFICATE_TLS_AUTH = new SourceAccessConfigurationType('CLIENT_CERTIFICATE_TLS_AUTH');\n\n  /** A custom source access configuration property */\n  public static of(name: string): SourceAccessConfigurationType {\n    return new SourceAccessConfigurationType(name);\n  }\n\n  /**\n   * The key to use in `SourceAccessConfigurationProperty.Type` property in CloudFormation\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lambda-eventsourcemapping-sourceaccessconfiguration.html#cfn-lambda-eventsourcemapping-sourceaccessconfiguration-type\n   */\n  public readonly type: string;\n\n  private constructor(type: string) {\n    this.type = type;\n  }\n}\n\n/**\n * Specific settings like the authentication protocol or the VPC components to secure access to your event source.\n */\nexport interface SourceAccessConfiguration {\n  /**\n   * The type of authentication protocol or the VPC components for your event source. For example: \"SASL_SCRAM_512_AUTH\".\n   */\n  readonly type: SourceAccessConfigurationType,\n  /**\n   * The value for your chosen configuration in type.\n   * For example: \"URI\": \"arn:aws:secretsmanager:us-east-1:01234567890:secret:MyBrokerSecretName\".\n   * The exact string depends on the type.\n   * @see SourceAccessConfigurationType\n   */\n  readonly uri: string\n}\n\nexport interface EventSourceMappingOptions {\n  /**\n   * The Amazon Resource Name (ARN) of the event source. Any record added to\n   * this stream can invoke the Lambda function.\n   *\n   * @default - not set if using a self managed Kafka cluster, throws an error otherwise\n   */\n  readonly eventSourceArn?: string;\n\n  /**\n   * The largest number of records that AWS Lambda will retrieve from your event\n   * source at the time of invoking your function. Your function receives an\n   * event with all the retrieved records.\n   *\n   * Valid Range: Minimum value of 1. Maximum value of 10000.\n   *\n   * @default - Amazon Kinesis, Amazon DynamoDB, and Amazon MSK is 100 records.\n   * The default for Amazon SQS is 10 messages. For standard SQS queues, the maximum is 10,000. For FIFO SQS queues, the maximum is 10.\n   */\n  readonly batchSize?: number;\n\n  /**\n   * If the function returns an error, split the batch in two and retry.\n   *\n   * @default false\n   */\n  readonly bisectBatchOnError?: boolean;\n\n  /**\n   * An Amazon SQS queue or Amazon SNS topic destination for discarded records.\n   *\n   * @default discarded records are ignored\n   */\n  readonly onFailure?: IEventSourceDlq;\n\n  /**\n   * Set to false to disable the event source upon creation.\n   *\n   * @default true\n   */\n  readonly enabled?: boolean;\n\n  /**\n   * The position in the DynamoDB, Kinesis or MSK stream where AWS Lambda should\n   * start reading.\n   *\n   * @see https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#Kinesis-GetShardIterator-request-ShardIteratorType\n   *\n   * @default - Required for Amazon Kinesis, Amazon DynamoDB, and Amazon MSK Streams sources.\n   */\n  readonly startingPosition?: StartingPosition;\n\n  /**\n   * Allow functions to return partially successful responses for a batch of records.\n   *\n   * @see https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-ddb-batchfailurereporting\n   *\n   * @default false\n   */\n  readonly reportBatchItemFailures?: boolean;\n\n  /**\n   * The maximum amount of time to gather records before invoking the function.\n   * Maximum of Duration.minutes(5)\n   *\n   * @default Duration.seconds(0)\n   */\n  readonly maxBatchingWindow?: cdk.Duration;\n\n  /**\n   * The maximum age of a record that Lambda sends to a function for processing.\n   * Valid Range:\n   * * Minimum value of 60 seconds\n   * * Maximum value of 7 days\n   *\n   * @default - infinite or until the record expires.\n   */\n  readonly maxRecordAge?: cdk.Duration;\n\n  /**\n   * The maximum number of times to retry when the function returns an error.\n   * Set to `undefined` if you want lambda to keep retrying infinitely or until\n   * the record expires.\n   *\n   * Valid Range:\n   * * Minimum value of 0\n   * * Maximum value of 10000\n   *\n   * @default - infinite or until the record expires.\n   */\n  readonly retryAttempts?: number;\n\n  /**\n   * The number of batches to process from each shard concurrently.\n   * Valid Range:\n   * * Minimum value of 1\n   * * Maximum value of 10\n   *\n   * @default 1\n   */\n  readonly parallelizationFactor?: number;\n\n  /**\n   * The name of the Kafka topic.\n   *\n   * @default - no topic\n   */\n  readonly kafkaTopic?: string;\n\n  /**\n   * The size of the tumbling windows to group records sent to DynamoDB or Kinesis\n   *\n   * @see https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-ddb-windows\n   *\n   * Valid Range: 0 - 15 minutes\n   *\n   * @default - None\n   */\n  readonly tumblingWindow?: cdk.Duration;\n\n  /**\n   * A list of host and port pairs that are the addresses of the Kafka brokers in a self managed \"bootstrap\" Kafka cluster\n   * that a Kafka client connects to initially to bootstrap itself.\n   * They are in the format `abc.example.com:9096`.\n   *\n   * @default - none\n   */\n  readonly kafkaBootstrapServers?: string[]\n\n  /**\n   * Specific settings like the authentication protocol or the VPC components to secure access to your event source.\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lambda-eventsourcemapping-sourceaccessconfiguration.html\n   *\n   * @default - none\n   */\n  readonly sourceAccessConfigurations?: SourceAccessConfiguration[]\n}\n\n/**\n * Properties for declaring a new event source mapping.\n */\nexport interface EventSourceMappingProps extends EventSourceMappingOptions {\n  /**\n   * The target AWS Lambda function.\n   */\n  readonly target: IFunction;\n}\n\n/**\n * Represents an event source mapping for a lambda function.\n * @see https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html\n */\nexport interface IEventSourceMapping extends cdk.IResource {\n  /**\n   * The identifier for this EventSourceMapping\n   * @attribute\n   */\n  readonly eventSourceMappingId: string;\n}\n\n/**\n * Defines a Lambda EventSourceMapping resource.\n *\n * Usually, you won't need to define the mapping yourself. This will usually be done by\n * event sources. For example, to add an SQS event source to a function:\n *\n *    import { SqsEventSource } from '@aws-cdk/aws-lambda-event-sources';\n *    lambda.addEventSource(new SqsEventSource(sqs));\n *\n * The `SqsEventSource` class will automatically create the mapping, and will also\n * modify the Lambda's execution role so it can consume messages from the queue.\n */\nexport class EventSourceMapping extends cdk.Resource implements IEventSourceMapping {\n\n  /**\n   * Import an event source into this stack from its event source id.\n   */\n  public static fromEventSourceMappingId(scope: Construct, id: string, eventSourceMappingId: string): IEventSourceMapping {\n    class Import extends cdk.Resource implements IEventSourceMapping {\n      public readonly eventSourceMappingId = eventSourceMappingId;\n    }\n    return new Import(scope, id);\n  }\n\n  public readonly eventSourceMappingId: string;\n\n  constructor(scope: Construct, id: string, props: EventSourceMappingProps) {\n    super(scope, id);\n\n    if (props.eventSourceArn == undefined && props.kafkaBootstrapServers == undefined) {\n      throw new Error('Either eventSourceArn or kafkaBootstrapServers must be set');\n    }\n\n    if (props.eventSourceArn !== undefined && props.kafkaBootstrapServers !== undefined) {\n      throw new Error('eventSourceArn and kafkaBootstrapServers are mutually exclusive');\n    }\n\n    if (props.kafkaBootstrapServers && (props.kafkaBootstrapServers?.length < 1)) {\n      throw new Error('kafkaBootStrapServers must not be empty if set');\n    }\n\n    if (props.maxBatchingWindow && props.maxBatchingWindow.toSeconds() > 300) {\n      throw new Error(`maxBatchingWindow cannot be over 300 seconds, got ${props.maxBatchingWindow.toSeconds()}`);\n    }\n\n    if (props.maxRecordAge && (props.maxRecordAge.toSeconds() < 60 || props.maxRecordAge.toDays({ integral: false }) > 7)) {\n      throw new Error('maxRecordAge must be between 60 seconds and 7 days inclusive');\n    }\n\n    props.retryAttempts !== undefined && cdk.withResolved(props.retryAttempts, (attempts) => {\n      if (attempts < 0 || attempts > 10000) {\n        throw new Error(`retryAttempts must be between 0 and 10000 inclusive, got ${attempts}`);\n      }\n    });\n\n    props.parallelizationFactor !== undefined && cdk.withResolved(props.parallelizationFactor, (factor) => {\n      if (factor < 1 || factor > 10) {\n        throw new Error(`parallelizationFactor must be between 1 and 10 inclusive, got ${factor}`);\n      }\n    });\n\n    if (props.tumblingWindow && !cdk.Token.isUnresolved(props.tumblingWindow) && props.tumblingWindow.toSeconds() > 900) {\n      throw new Error(`tumblingWindow cannot be over 900 seconds, got ${props.tumblingWindow.toSeconds()}`);\n    }\n\n\n    let destinationConfig;\n\n    if (props.onFailure) {\n      destinationConfig = {\n        onFailure: props.onFailure.bind(this, props.target),\n      };\n    }\n\n    let selfManagedEventSource;\n    if (props.kafkaBootstrapServers) {\n      selfManagedEventSource = { endpoints: { kafkaBootstrapServers: props.kafkaBootstrapServers } };\n    }\n\n    const cfnEventSourceMapping = new CfnEventSourceMapping(this, 'Resource', {\n      batchSize: props.batchSize,\n      bisectBatchOnFunctionError: props.bisectBatchOnError,\n      destinationConfig,\n      enabled: props.enabled,\n      eventSourceArn: props.eventSourceArn,\n      functionName: props.target.functionName,\n      startingPosition: props.startingPosition,\n      functionResponseTypes: props.reportBatchItemFailures ? ['ReportBatchItemFailures'] : undefined,\n      maximumBatchingWindowInSeconds: props.maxBatchingWindow?.toSeconds(),\n      maximumRecordAgeInSeconds: props.maxRecordAge?.toSeconds(),\n      maximumRetryAttempts: props.retryAttempts,\n      parallelizationFactor: props.parallelizationFactor,\n      topics: props.kafkaTopic !== undefined ? [props.kafkaTopic] : undefined,\n      tumblingWindowInSeconds: props.tumblingWindow?.toSeconds(),\n      sourceAccessConfigurations: props.sourceAccessConfigurations?.map((o) => {return { type: o.type.type, uri: o.uri };}),\n      selfManagedEventSource,\n    });\n    this.eventSourceMappingId = cfnEventSourceMapping.ref;\n  }\n}\n\n/**\n * The position in the DynamoDB, Kinesis or MSK stream where AWS Lambda should start\n * reading.\n */\nexport enum StartingPosition {\n  /**\n   * Start reading at the last untrimmed record in the shard in the system,\n   * which is the oldest data record in the shard.\n   */\n  TRIM_HORIZON = 'TRIM_HORIZON',\n\n  /**\n   * Start reading just after the most recent record in the shard, so that you\n   * always read the most recent data in the shard\n   */\n  LATEST = 'LATEST',\n}\n"],
  "mappings": "2RAAA,IAAA,QAAA,YAAA,EAIA,mBAAA,QAAA,oBAAA,EAMA,MAAa,6BAA6B,CA4CxC,YAAoB,KAAY,CAC9B,KAAK,KAAO,WAXA,IAAG,KAAY,CAC3B,MAAO,IAAI,+BAA8B,IAAI,GAnCjD,QAAA,8BAAA,oKAKyB,8BAAA,WAAa,GAAI,+BAA8B,YAAY,EAK3D,8BAAA,WAAa,GAAI,+BAA8B,YAAY,EAK3D,8BAAA,mBAAqB,GAAI,+BAA8B,oBAAoB,EAK3E,8BAAA,oBAAsB,GAAI,+BAA8B,qBAAqB,EAK7E,8BAAA,oBAAsB,GAAI,+BAA8B,qBAAqB,EAM7E,8BAAA,4BAA8B,GAAI,+BAA8B,6BAA6B,EA+MtH,MAAa,0BAA2B,KAAI,QAAQ,CAclD,YAAY,MAAkB,GAAY,MAA8B,oBACtE,MAAM,MAAO,EAAE,EAEf,iFAAI,MAAM,gBAAkB,MAAa,MAAM,uBAAyB,KACtE,KAAM,IAAI,OAAM,4DAA4D,EAG9E,GAAI,MAAM,iBAAmB,QAAa,MAAM,wBAA0B,OACxE,KAAM,IAAI,OAAM,iEAAiE,EAGnF,GAAI,MAAM,uBAA0B,KAAA,MAAM,yBAAqB,MAAA,KAAA,OAAA,OAAA,GAAE,QAAS,EACxE,KAAM,IAAI,OAAM,gDAAgD,EAGlE,GAAI,MAAM,mBAAqB,MAAM,kBAAkB,UAAS,EAAK,IACnE,KAAM,IAAI,OAAM,qDAAqD,MAAM,kBAAkB,UAAS,GAAI,EAG5G,GAAI,MAAM,cAAiB,OAAM,aAAa,UAAS,EAAK,IAAM,MAAM,aAAa,OAAO,CAAE,SAAU,EAAK,CAAE,EAAI,GACjH,KAAM,IAAI,OAAM,8DAA8D,EAehF,GAZA,MAAM,gBAAkB,QAAa,IAAI,aAAa,MAAM,cAAe,AAAC,UAAY,CACtF,GAAI,SAAW,GAAK,SAAW,IAC7B,KAAM,IAAI,OAAM,4DAA4D,UAAU,CAE1F,CAAC,EAED,MAAM,wBAA0B,QAAa,IAAI,aAAa,MAAM,sBAAuB,AAAC,QAAU,CACpG,GAAI,OAAS,GAAK,OAAS,GACzB,KAAM,IAAI,OAAM,iEAAiE,QAAQ,CAE7F,CAAC,EAEG,MAAM,gBAAkB,CAAC,IAAI,MAAM,aAAa,MAAM,cAAc,GAAK,MAAM,eAAe,UAAS,EAAK,IAC9G,KAAM,IAAI,OAAM,kDAAkD,MAAM,eAAe,UAAS,GAAI,EAItG,GAAI,mBAEJ,AAAI,MAAM,WACR,mBAAoB,CAClB,UAAW,MAAM,UAAU,KAAK,KAAM,MAAM,MAAM,IAItD,GAAI,wBACJ,AAAI,MAAM,uBACR,wBAAyB,CAAE,UAAW,CAAE,sBAAuB,MAAM,qBAAqB,CAAE,GAG9F,KAAM,uBAAwB,GAAI,oBAAA,sBAAsB,KAAM,WAAY,CACxE,UAAW,MAAM,UACjB,2BAA4B,MAAM,mBAClC,kBACA,QAAS,MAAM,QACf,eAAgB,MAAM,eACtB,aAAc,MAAM,OAAO,aAC3B,iBAAkB,MAAM,iBACxB,sBAAuB,MAAM,wBAA0B,CAAC,yBAAyB,EAAI,OACrF,+BAA8B,IAAE,MAAM,qBAAiB,MAAA,KAAA,OAAA,OAAA,GAAE,UAAS,EAClE,0BAAyB,IAAE,MAAM,gBAAY,MAAA,KAAA,OAAA,OAAA,GAAE,UAAS,EACxD,qBAAsB,MAAM,cAC5B,sBAAuB,MAAM,sBAC7B,OAAQ,MAAM,aAAe,OAAY,CAAC,MAAM,UAAU,EAAI,OAC9D,wBAAuB,IAAE,MAAM,kBAAc,MAAA,KAAA,OAAA,OAAA,GAAE,UAAS,EACxD,2BAA0B,IAAE,MAAM,8BAA0B,MAAA,KAAA,OAAA,OAAA,GAAE,IAAI,AAAC,GAAc,EAAE,KAAM,EAAE,KAAK,KAAM,IAAK,EAAE,GAAG,EAAI,EACpH,uBACD,EACD,KAAK,qBAAuB,sBAAsB,UAhFtC,0BAAyB,MAAkB,GAAY,qBAA4B,CAC/F,MAAM,cAAe,KAAI,QAAQ,CAAjC,aAAA,qBACkB,KAAA,qBAAuB,oBACzC,EACA,MAAO,IAAI,QAAO,MAAO,EAAE,GAT/B,QAAA,mBAAA,mIA6FA,GAAY,kBAAZ,AAAA,UAAY,kBAAgB,CAK1B,kBAAA,aAAA,eAMA,kBAAA,OAAA,QACF,GAZY,iBAAA,QAAA,kBAAA,SAAA,iBAAgB,CAAA,EAAA",
  "names": []
}
